* Block Types

There will be two block type: ones where uncertain compounds result in
P(o1) and another where they result in P(o2).

** TODO Experiment 2

4 stim x 24 blocks
24x(2/3)=*16* blocks with P(o1) and 24*(1/3)=*8* blocks with P(o2)

*** STAGE 2

6 training blocks x 4 stim

* Trial Order
Tom's version randomizes across blocks, while my version randomizes
within blocks. It should not affect the overall outcome, although
LePelley and McLaren randomized within block - just good to know if we
want to include the data set.
* Funny Solutions
** replicating matrices
Instead of using the pracma package, I used do.call(rbind, replicate(number,
matrix)), because it is much faster.
** updating alpha
The way Tom calculated the magnitude of prediction errors for alpha (by
which it is essentially updated) is a bit hard to do for a state list
processor. The reason is that slpMK75 will need to be able to handle
as many cues at the same time as we want. For this reason I picked the
equation presented in Le Pelley et al. (2016). This produces the same
result - I checked it on paper as proof, but we can write a script to
prove it though.
** only used outcome 1
In line with other single linear operators implemented in catlearn (RW, BM),
slpMK75 only uses one column for outcomes. I can imagine two ways to solve
this. First, we use -1 instead of 0. It seems to work like a charm. Another
is to run another sim, but for outcome 2. It can be done by tr[, "t"] <- 
abs(tr[, "t"] - 1). I would pick the version with -1, because that is the
computationally less intensive.
** reset weights but not alphas
I think it might be useful if the function can reset weights but not alphas.
For example, there might be a new outcome, where the stimuli remains the
same. In that case, the state last processor can simply reset weight and
start learning. This solution is necessary because of the binary
representation of input and having only one t column. I see no reason to
reset alphas without resetting the weights as well, let me know of you find
one.
* Debugging
** Naming things
Naming things is not easy...
function: slpMK75
train of ap: lepelleymclaren2003train
sim: lepelleymclaren2003mk75
** Data frame problems
There was some problem with how I extracted elements of a list as a data
frame and not a numerical matrix. This cause the Rcpp function to end with an
error message: Not compatible with requested type: [type=list; target=double].
This has been fixed and was not related to either tr or slpMK75.
** S2 alpha error
During the second stage, after the first few trials, something happens to the
alphas that causes them to change high values to 0.1 instead of 1. I don't
really know why it is happening, but working on it heavily. The error is
reproducible, so it should not take long to fix it. If anyone is interested
in taking a look, look at values from trials 160-165.
#+BEGIN_SRC R
slpMK75(st, lepelleymclaren2003ap()[[1]], xtdo = TRUE)$xouta[160:165, ]
slpMK75(st, lepelleymclaren2003ap()[[1]], xtdo = TRUE)$xoutw[160:165, ]
#+END_SRC
Outputs from S1 looks pretty promising though!!
